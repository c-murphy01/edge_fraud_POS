{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e97f4e0",
   "metadata": {},
   "source": [
    "## Baseline Detector Evaluation (Merchant)\n",
    "\n",
    "Evaluate the simple threshold rule for detecting velocity spikes in the sparkov + synthetic spikes dataset, then check against the real world Caixa data.\n",
    "\n",
    "### Method\n",
    "\n",
    " - Count number of unique cards per merchant in 30s buckets\n",
    " - Raise a flag if the count is greater than the set threshold\n",
    " - Compare predictions to the ground truth - MERCHANT_SET (pairs of merchant_id, bucket_30s)\n",
    "\n",
    " Use per bucket, not per transaction, to avoid over counting. Bucket is flagged once whether 10 or 100 transactions in 30s window."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804de7c5",
   "metadata": {},
   "source": [
    "### Streamed Data Evaluation\n",
    "\n",
    "Stream the dataset once through, update the per merchant unique card count on each Tx, flag bucket once the count is greater than the threshold, calculate confusion matrix based on all merchant/bucket pairs. This mirrors what the Raspberry Pi will do on live card taps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df0bfc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "#create absoulute path to notebook's. parent directory to src\n",
    "module_path = os.path.abspath(os.path.join('..', 'src'))\n",
    "#add to sys.path if not already there\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "#import detector wrapper functions\n",
    "from baseline_detector import MerchantBaseline, CardBaseline\n",
    "#import the merchant and card sets from truth tables\n",
    "from truth_tables import MERCHANT_SET, CARD_SET\n",
    "#inport evaluation helper functions\n",
    "from eval_funcs import threshold_predictions, per_bucket_confusion, precision_recall_f1, sweep_thresholds\n",
    "\n",
    "#ensure constistent d types\n",
    "DTYPES = {\"merchant_id\": str, \"card_id\": str, \"zip\": str}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbf9a7a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP 50 FP 0 FN 0 TN 1555392\n",
      "precision 1.000 recall 1.000 F1 1.000\n"
     ]
    }
   ],
   "source": [
    "# #read in spiked dataset, parsing timestamp as a time object, setting merchant and card ids to strings\n",
    "# #set low memory false to avoid incorrect data type inferences\n",
    "df = pd.read_csv(\n",
    "    \"../data/processed/sparkov_spikes.csv\",\n",
    "    parse_dates=[\"timestamp\"],\n",
    "    dtype=DTYPES,\n",
    "    low_memory=False\n",
    ")\n",
    "\n",
    "#define initial merchant spike baseline\n",
    "THRESHOLD_M = 6\n",
    "\n",
    "# #create instance of merchant baseline class\n",
    "mb = MerchantBaseline(threshold=THRESHOLD_M)\n",
    "\n",
    "#create empty sets for predictions and coverage\n",
    "predicted = set() #set of (merchant_id, bucket) that we flag\n",
    "all_buckets = set() #set of all (merchant_id, buckets) streamed in\n",
    "\n",
    "for row in df.itertuples():\n",
    "    #call the baseline wrapper class' update function\n",
    "    flag, info = mb.update(row.merchant_id, row.timestamp, row.card_id)\n",
    "    bucket = info[\"bucket\"]\n",
    "    #add each to the all bucekts set\n",
    "    all_buckets.add((row.merchant_id, bucket))\n",
    "    #add to flagged set if over threshold\n",
    "    if flag:\n",
    "        predicted.add((row.merchant_id, bucket))\n",
    "\n",
    "#find confusion matrix\n",
    "cm = per_bucket_confusion(predicted, MERCHANT_SET, all_buckets)\n",
    "#calc precision, recall, and f1 scores\n",
    "m  = precision_recall_f1(cm[\"tp\"], cm[\"fp\"], cm[\"fn\"])\n",
    "\n",
    "#print results\n",
    "print(f\"TP {cm['tp']} FP {cm['fp']} FN {cm['fn']} TN {cm['tn']}\")\n",
    "print(f\"precision {m['precision']:.3f} recall {m['recall']:.3f} F1 {m['f1']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35fb091",
   "metadata": {},
   "source": [
    "### Varied Threshold Test\n",
    "\n",
    "Compute the unique cards per mechant/bucket once, then sweep through different thresholds 2-8, calculate and compare precision/recall against the ground truth. Choose the smallest threshold that gives perfect or near perfect recall on the synthetic data and will likely stay quiet on real data such as the Caixa dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3473959c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'th': 2, 'tp': 50, 'fp': 2297, 'fn': 0, 'tn': 1553095, 'precision': 0.021303792074989347, 'recall': 1.0, 'f1': 0.04171881518564872}\n",
      "{'th': 3, 'tp': 50, 'fp': 2, 'fn': 0, 'tn': 1555390, 'precision': 0.9615384615384616, 'recall': 1.0, 'f1': 0.9803921568627451}\n",
      "{'th': 4, 'tp': 50, 'fp': 0, 'fn': 0, 'tn': 1555392, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0}\n",
      "{'th': 5, 'tp': 50, 'fp': 0, 'fn': 0, 'tn': 1555392, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0}\n",
      "{'th': 6, 'tp': 50, 'fp': 0, 'fn': 0, 'tn': 1555392, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0}\n",
      "{'th': 7, 'tp': 50, 'fp': 0, 'fn': 0, 'tn': 1555392, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0}\n",
      "{'th': 8, 'tp': 50, 'fp': 0, 'fn': 0, 'tn': 1555392, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0}\n",
      "truth merchant spikes: 50\n",
      "merchant-buckets total: 1555442\n"
     ]
    }
   ],
   "source": [
    "#add a bucket column to the dataframe (flooring same as detector/truth table)\n",
    "df[\"bucket\"] = df[\"timestamp\"].dt.floor(\"30s\")\n",
    "\n",
    "#count unique cards per merchant\n",
    "counts_m = df.groupby([\"merchant_id\", \"bucket\"])[\"card_id\"].nunique()\n",
    "#convert to a dictionary of key: (merchant, bucket), value: count or unique cards\n",
    "counts_m_dict = {k: int(v) for k, v in counts_m.items()}\n",
    "#all merchant/bucket pairs (used to find number of true negatives)\n",
    "all_buckets = set(counts_m_dict.keys())\n",
    "\n",
    "results = sweep_thresholds(counts_m_dict, MERCHANT_SET, all_buckets, start=2, stop=8)\n",
    "for r in results:\n",
    "    print(r)\n",
    "\n",
    "print(\"truth merchant spikes:\", len(MERCHANT_SET))\n",
    "print(\"merchant-buckets total:\", counts_m.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e47121b",
   "metadata": {},
   "source": [
    "### Choose Threshold Going Forward\n",
    "\n",
    "In this case, a threshold from 4 to 8 gives the same perfect results. Keep threshold at 6 for the baseline rule to add a margin for unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe10a89d",
   "metadata": {},
   "source": [
    "### Caixa Dataset Alert Rate Test\n",
    "\n",
    "Run the Real-Life Dataset (Caixa) through the baseline detector.\n",
    "This will estimate how the rule will fire on real transaction traffic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba4ec375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "th=4: 254/6692434  (0.00380%)\n",
      "th=5: 10/6692434  (0.00015%)\n",
      "th=6: 1/6692434  (0.00001%)\n",
      "th=7: 0/6692434  (0.00000%)\n",
      "th=8: 0/6692434  (0.00000%)\n"
     ]
    }
   ],
   "source": [
    "#read in caixa datset\n",
    "dfc = pd.read_csv(\"../data/processed/caixa_pos_sorted.csv\",\n",
    "                  parse_dates=[\"timestamp\"],\n",
    "                  dtype=DTYPES,\n",
    "                  low_memory=False)\n",
    "\n",
    "#add a bucket column to the dataframe (flooring same as detector/truth table)\n",
    "dfc[\"bucket\"] = dfc[\"timestamp\"].dt.floor(\"30s\")\n",
    "#count unique cards per merchant\n",
    "counts_m_c = dfc.groupby([\"merchant_id\",\"bucket\"])[\"card_id\"].nunique()\n",
    "\n",
    "#for various threshold values\n",
    "for THRESHOLD in [4,5,6,7,8]:\n",
    "    #count number of merchant/bucket pairs flagged as fraud\n",
    "    num_flagged   = int((counts_m_c >= THRESHOLD).sum())\n",
    "    #number of total merchant/bucket pairs\n",
    "    total_buckets = int(counts_m_c.size)\n",
    "    #calculate rate of false positives\n",
    "    rate = num_flagged / total_buckets if total_buckets else 0.0\n",
    "    #print results\n",
    "    print(f\"th={THRESHOLD}: {num_flagged}/{total_buckets}  ({rate:.5%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a99b66",
   "metadata": {},
   "source": [
    "At the threshold of 6, the rule only fires once in ~6.7m buckets in the Caixa data. We know there are no actual velocity spikes in this data, so this essentially means we have one false positive. This is nerly perfect so we will keep THRESHOLD_M = 6."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c99df4",
   "metadata": {},
   "source": [
    "## Baseline Detector Evaluation (Card Burst)\n",
    "Evaluate the simple threshold rule for detecting card bursts in the sparkov + synthetic spikes dataset, then test on Caixa data.\n",
    "\n",
    "### Method\n",
    "\n",
    " - Count number of unique merchants per card in 30s buckets\n",
    " - Raise a flag if the count is greater than the set threshold\n",
    " - Compare predictions to the ground truth - CARD_SET (list of which cards were spiked)\n",
    " \n",
    "A card counts as detected if it is flagged at least once."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625f7b4b",
   "metadata": {},
   "source": [
    "### Streamed Data Evaluation\n",
    "\n",
    "Stream the dataset once through, update the per card unique mercahnt count on each Tx, flag bucket once the count is greater than the threshold, calculate confusion matrix based on all card/bucket pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3dcf66a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP 41 FP 0 FN 9 TN 1749\n",
      "precision 1.000 recall 0.820 F1 0.901\n"
     ]
    }
   ],
   "source": [
    "#set static baseline threshold of 4\n",
    "THRESHOLD_C = 4\n",
    "\n",
    "#create instance of card baseline class\n",
    "cb   = CardBaseline(threshold=THRESHOLD_C)\n",
    "\n",
    "#create empty sets for predictions and coverage\n",
    "predicted_cards = set() #set of card_ids that are flagged\n",
    "all_cards = set(df[\"card_id\"].astype(str)) #set of all card_ids\n",
    "\n",
    "\n",
    "for row in df.itertuples():\n",
    "    #call the baseline wrapper class' update function\n",
    "    flag, info = cb.update(row.card_id, row.timestamp, row.merchant_id)\n",
    "    #add to flagged set if over threshold\n",
    "    if flag:\n",
    "        predicted_cards.add(row.card_id)\n",
    "\n",
    "#find confusion matrix\n",
    "cm_c = per_bucket_confusion(predicted_cards, CARD_SET, all_cards)\n",
    "#calc precision, recall, and f1 scores\n",
    "m_c  = precision_recall_f1(cm_c[\"tp\"], cm_c[\"fp\"], cm_c[\"fn\"])\n",
    "\n",
    "#print results\n",
    "print(f\"TP {cm_c['tp']} FP {cm_c['fp']} FN {cm_c['fn']} TN {cm_c['tn']}\")\n",
    "print(f\"precision {m_c['precision']:.3f} recall {m_c['recall']:.3f} F1 {m_c['f1']:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8396e53",
   "metadata": {},
   "source": [
    "### Varied Threshold Test\n",
    "\n",
    "The set threshold resulted in some false negatives. Now sweep through different thresholds 2-7, calculate and compare results for each threshold. \n",
    "Because the ground truth (CARD_SET) is card-level, collapse the predicted (card, bucket) set to just cards and calculate metrics at card level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c31a727f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'th': 2, 'tp': 50, 'fp': 492, 'fn': 0, 'tn': 1257, 'precision': 0.09225092250922509, 'recall': 1.0, 'f1': 0.16891891891891891}\n",
      "{'th': 3, 'tp': 49, 'fp': 0, 'fn': 1, 'tn': 1749, 'precision': 1.0, 'recall': 0.98, 'f1': 0.98989898989899}\n",
      "{'th': 4, 'tp': 41, 'fp': 0, 'fn': 9, 'tn': 1749, 'precision': 1.0, 'recall': 0.82, 'f1': 0.9010989010989011}\n",
      "{'th': 5, 'tp': 0, 'fp': 0, 'fn': 50, 'tn': 1749, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0}\n",
      "{'th': 6, 'tp': 0, 'fp': 0, 'fn': 50, 'tn': 1749, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0}\n",
      "{'th': 7, 'tp': 0, 'fp': 0, 'fn': 50, 'tn': 1749, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0}\n"
     ]
    }
   ],
   "source": [
    "#counts unique merchants per card_id/bucket\n",
    "counts_c = df.groupby([\"card_id\", \"bucket\"])[\"merchant_id\"].nunique()\n",
    "#set up counts dictionary with key: card_id, bucket and value: unique merchant count\n",
    "counts_c_dict = {k: int(v) for k, v in counts_c.items()}\n",
    "#create set of all card_ids\n",
    "all_cards = set(df[\"card_id\"].astype(str))\n",
    "\n",
    "#define new functions for sweep of card thresholds\n",
    "def card_metrics_at(th):\n",
    "    #get prediced pairs (card_id, bucket)\n",
    "    pred_pairs = threshold_predictions(counts_c_dict, th)\n",
    "    #collapse the predicted pairs to just the card ids (which ones have been flagged)\n",
    "    pred_cards = {cid for (cid, _) in pred_pairs}\n",
    "\n",
    "    #calculste confusion at the card level (sets of card_ids)\n",
    "    cm = per_bucket_confusion(pred_cards, CARD_SET, all_cards)\n",
    "    #calculate evaluation metrics\n",
    "    m  = precision_recall_f1(cm[\"tp\"], cm[\"fp\"], cm[\"fn\"])\n",
    "    #return the threshold, confusion matrix and evaluation scores \n",
    "    #(** unpacks the dictionary to allow us to create a new one)\n",
    "    return {\"th\": th, **cm, **m}\n",
    "\n",
    "#print the results for each threshold\n",
    "for th in range(2, 8):\n",
    "    print(card_metrics_at(th))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64848123",
   "metadata": {},
   "source": [
    "### Choose Threshold Going Forward\n",
    "\n",
    "We want the lowest threshold with full recall on the synthetic data. Once the threshold goes above 3 we begin to see false negatives. The threshold will be set to 3 as it gives almost perfect recall on the synthetic data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1b1b71",
   "metadata": {},
   "source": [
    "### Caixa Dataset Alert Rate Test\n",
    "\n",
    "Run the Real-Life Dataset (Caixa) through the baseline detector to check for false positives (no card bursts in data so any flags can be read as false positives).\n",
    "Keep/change the curresnt threshold rule based on results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "936d26de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "th=2: pair-rate 3556/6825428 (0.05210%); card-rate 1382/4065 (33.99754%)\n",
      "th=3: pair-rate 1/6825428 (0.00001%); card-rate 1/4065 (0.02460%)\n",
      "th=4: pair-rate 0/6825428 (0.00000%); card-rate 0/4065 (0.00000%)\n"
     ]
    }
   ],
   "source": [
    "#set threshold to value decided above, 3\n",
    "THRESHOLD_C = 3\n",
    "\n",
    "#count of how many unique merchants each card has visited that window\n",
    "counts_c_c = dfc.groupby([\"card_id\",\"bucket\"])[\"merchant_id\"].nunique()\n",
    "\n",
    "#test several cart thresholds on the real data\n",
    "for TH in [2,3,4]:\n",
    "    #number of card/buckets that meet threshold\n",
    "    pair_flags = int((counts_c_c >= TH).sum())\n",
    "    #total number of card/bucket pairs\n",
    "    pair_total = int(counts_c_c.size)\n",
    "    #share of card/buckets flagged at thos threshold (safe division)\n",
    "    pair_rate  = pair_flags / pair_total if pair_total else 0.0\n",
    "\n",
    "    #count of how many unique cards would be flagged at this threshold\n",
    "    #reset_index() turns card/bucket pairs into columns so we can extract card_id\n",
    "    cards_flagged = counts_c_c[counts_c_c >= TH].reset_index()[\"card_id\"].astype(str).nunique()\n",
    "    #total count of unique cards\n",
    "    total_cards   = dfc[\"card_id\"].astype(str).nunique()\n",
    "    #share of cards flagged at least once (safe division)\n",
    "    card_rate     = cards_flagged / total_cards if total_cards else 0.0\n",
    "\n",
    "    #print results\n",
    "    print(f\"th={TH}: pair-rate {pair_flags}/{pair_total} ({pair_rate:.5%}); \"\n",
    "          f\"card-rate {cards_flagged}/{total_cards} ({card_rate:.5%})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af74979",
   "metadata": {},
   "source": [
    "Threshold of 3 stays quiet on the Caixa data so we will keep it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c6e8f5",
   "metadata": {},
   "source": [
    "## Add Card Focused Amount Rules\n",
    "\n",
    "Two amount based card rules:\n",
    "- Static Cap: flags transactions over a fixed amount cap. This catches obvious outliers\n",
    "- Card EWMA: tracks per card log(amount) with an exponentially weighted moving average. Raises a flag if z score > k value. Apply a minimum amount gate prevents small amounts from generating large z scores\n",
    "\n",
    "Evaluate the rules with some initial estimates to ensure they work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9fc4e09d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AmountCap: 2076 tx flagged (0.03025% of tx), distinct cards: 603\n",
      "CardEWMA: 6612 tx flagged (0.09633% of tx), distinct cards: 1879\n"
     ]
    }
   ],
   "source": [
    "from baseline_detector import AmountCap, CardEWMA\n",
    "\n",
    "#set starting values for parameters\n",
    "CAP = 1200.0\n",
    "ALPHA = 0.2\n",
    "K = 2.5\n",
    "INITIAL = 2\n",
    "MIN_GATE = 500\n",
    "\n",
    "#instantiate amount cap and card ewma classes with above parameters\n",
    "ac = AmountCap(cap=CAP)\n",
    "cewma = CardEWMA(alpha=ALPHA, k=K, initial=INITIAL, min_gate=MIN_GATE)\n",
    "\n",
    "#counter for flags due to each rule\n",
    "cap_flags = 0\n",
    "ewma_flags = 0\n",
    "#sets to hold card id's that are flagged\n",
    "cap_cards = set()\n",
    "ewma_cards = set()\n",
    "\n",
    "#loop through caixa dataset to estimate false-positive rates for these rules\n",
    "for row in dfc.itertuples():\n",
    "    #static cap check - if amount > cap, flag (add to counter and add card id to set)\n",
    "    if ac.update(row.amount):\n",
    "        cap_flags += 1\n",
    "        cap_cards.add(row.card_id)\n",
    "\n",
    "    #adaptive amount check: flag if unusually large for this card\n",
    "    f, info = cewma.update(row.card_id, row.amount)\n",
    "    #add to counter and add card to set if flag is raised\n",
    "    if f:\n",
    "        ewma_flags += 1\n",
    "        ewma_cards.add(row.card_id)\n",
    "\n",
    "#show how many transactions (+ flag rate) and cards were flagged for cap rule\n",
    "print(f\"AmountCap: {cap_flags} tx flagged ({cap_flags / len(dfc):.5%} of tx), \"\n",
    "      f\"distinct cards: {len(cap_cards)}\")\n",
    "\n",
    "#show how many transactions (+ flag rate) and cards were flagged for ewma rule\n",
    "print(f\"CardEWMA: {ewma_flags} tx flagged ({ewma_flags / len(dfc):.5%} of tx), \"\n",
    "      f\"distinct cards: {len(ewma_cards)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42d4542",
   "metadata": {},
   "source": [
    "### Tune Parameters for Better Results\n",
    "\n",
    "- Look at high quantiles for amount data to find candidates for amount cap.\n",
    "- Sweep over the candidates to find the largest one that keeps the Tx rate acceptably low\n",
    "\n",
    "There are no ground truths for this data so we use the Caixa data and aim for low false positive rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a755e4f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9950     431.00\n",
      "0.9990     871.25\n",
      "0.9995    1063.73\n",
      "0.9999    1477.01\n",
      "Name: amount, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cap</th>\n",
       "      <th>flag_tx</th>\n",
       "      <th>tx_rate</th>\n",
       "      <th>flag_cards</th>\n",
       "      <th>card_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1600</td>\n",
       "      <td>414</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>150</td>\n",
       "      <td>0.036900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1500</td>\n",
       "      <td>614</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>206</td>\n",
       "      <td>0.050677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1400</td>\n",
       "      <td>960</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>323</td>\n",
       "      <td>0.079459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1250</td>\n",
       "      <td>1718</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>509</td>\n",
       "      <td>0.125215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    cap  flag_tx   tx_rate  flag_cards  card_rate\n",
       "3  1600      414  0.000060         150   0.036900\n",
       "2  1500      614  0.000089         206   0.050677\n",
       "1  1400      960  0.000140         323   0.079459\n",
       "0  1250     1718  0.000250         509   0.125215"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#look at amount distribution\n",
    "q = dfc[\"amount\"].quantile([0.995, 0.999, 0.9995, 0.9999]).round(2)\n",
    "print(q)\n",
    "\n",
    "#list of candidate thresholds\n",
    "candidates = sorted(set([\n",
    "    1250, 1400, 1500, 1600\n",
    "]))\n",
    "\n",
    "#empty list to hold results\n",
    "rows = []\n",
    "total_tx = len(dfc)\n",
    "#loop through each threshold\n",
    "for cap in candidates:\n",
    "    #instantiate amount cap object\n",
    "    ac = AmountCap(cap=cap)\n",
    "    #counter for flags and set for unique card ids\n",
    "    flags = 0\n",
    "    cards = set()\n",
    "    #iterate through dataframe\n",
    "    for row in dfc.itertuples():\n",
    "        #raise flag if amount exceeds cap\n",
    "        if ac.update(row.amount):\n",
    "            flags += 1\n",
    "            cards.add(row.card_id)\n",
    "    #append results to rows list\n",
    "    rows.append({\n",
    "        \"cap\": cap,\n",
    "        \"flag_tx\": flags,\n",
    "        \"tx_rate\": flags/total_tx,\n",
    "        \"flag_cards\": len(cards),\n",
    "        \"card_rate\": len(cards)/dfc[\"card_id\"].nunique()\n",
    "    })\n",
    "\n",
    "#sort by flagged transaction rate\n",
    "pd.DataFrame(rows).sort_values(\"tx_rate\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d36c6e",
   "metadata": {},
   "source": [
    "### Set Amount Cap\n",
    "\n",
    "Based on the results, a cap of 1500 provides coverage of very high spends while the transaction flag rate is sufficiently low ( < 0.1% )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75040a5e",
   "metadata": {},
   "source": [
    "### Sweep Other Parameters\n",
    "\n",
    "Test out a few values for alpha, k, initial (warm up) transactions, and minimum gates to find a combination that works best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b62a0918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>k</th>\n",
       "      <th>init</th>\n",
       "      <th>flag_tx</th>\n",
       "      <th>tx_rate</th>\n",
       "      <th>flag_cards</th>\n",
       "      <th>card_rate</th>\n",
       "      <th>gate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.1</td>\n",
       "      <td>5.50</td>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>21</td>\n",
       "      <td>0.005166</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.1</td>\n",
       "      <td>5.50</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>23</td>\n",
       "      <td>0.005658</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.1</td>\n",
       "      <td>5.25</td>\n",
       "      <td>10</td>\n",
       "      <td>26</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>26</td>\n",
       "      <td>0.006396</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.1</td>\n",
       "      <td>5.25</td>\n",
       "      <td>5</td>\n",
       "      <td>28</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>28</td>\n",
       "      <td>0.006888</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.1</td>\n",
       "      <td>5.50</td>\n",
       "      <td>10</td>\n",
       "      <td>34</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>33</td>\n",
       "      <td>0.008118</td>\n",
       "      <td>850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.1</td>\n",
       "      <td>5.00</td>\n",
       "      <td>10</td>\n",
       "      <td>36</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>31</td>\n",
       "      <td>0.007626</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.1</td>\n",
       "      <td>5.50</td>\n",
       "      <td>5</td>\n",
       "      <td>37</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>36</td>\n",
       "      <td>0.008856</td>\n",
       "      <td>850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.1</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5</td>\n",
       "      <td>38</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>33</td>\n",
       "      <td>0.008118</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.1</td>\n",
       "      <td>5.25</td>\n",
       "      <td>10</td>\n",
       "      <td>49</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>46</td>\n",
       "      <td>0.011316</td>\n",
       "      <td>850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.1</td>\n",
       "      <td>5.50</td>\n",
       "      <td>10</td>\n",
       "      <td>52</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>47</td>\n",
       "      <td>0.011562</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    alpha     k  init  flag_tx   tx_rate  flag_cards  card_rate  gate\n",
       "31    0.1  5.50    10       21  0.000003          21   0.005166  1000\n",
       "27    0.1  5.50     5       23  0.000003          23   0.005658  1000\n",
       "23    0.1  5.25    10       26  0.000004          26   0.006396  1000\n",
       "19    0.1  5.25     5       28  0.000004          28   0.006888  1000\n",
       "30    0.1  5.50    10       34  0.000005          33   0.008118   850\n",
       "15    0.1  5.00    10       36  0.000005          31   0.007626  1000\n",
       "26    0.1  5.50     5       37  0.000005          36   0.008856   850\n",
       "11    0.1  5.00     5       38  0.000006          33   0.008118  1000\n",
       "22    0.1  5.25    10       49  0.000007          46   0.011316   850\n",
       "29    0.1  5.50    10       52  0.000008          47   0.011562   750"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import importlib\n",
    "# import baseline_detector \n",
    "\n",
    "# importlib.reload(baseline_detector) \n",
    "\n",
    "#alpha test values\n",
    "alphas = [0.1, 0.2]\n",
    "#z score threshold\n",
    "test_ks     = [4.5, 5, 5.25, 5.5]\n",
    "#initial warm up values for transactions to see before scoring\n",
    "inits  = [5, 10]\n",
    "#set minimum gate values to test\n",
    "gates = [600, 750, 850, 1000]\n",
    "\n",
    "#list to hold results\n",
    "results = []\n",
    "total_tx = len(dfc)\n",
    "total_cards = dfc[\"card_id\"].nunique()\n",
    "\n",
    "#loop through each combination of parameters\n",
    "for a in alphas:\n",
    "    for test_k in test_ks:\n",
    "        for i in inits:\n",
    "            for gate in gates:\n",
    "                #instantiate CardEWMA with current parameters\n",
    "                cae = CardEWMA(alpha=a, k=test_k, initial=i, min_gate=gate)\n",
    "                flags = 0\n",
    "                cards = set()\n",
    "                #iterate through dataframe\n",
    "                for row in dfc.itertuples():\n",
    "                    f, _ = cae.update(row.card_id, row.amount)\n",
    "                    #if flag is raised, increment counter\n",
    "                    if f:\n",
    "                       flags += 1\n",
    "                       cards.add(row.card_id)\n",
    "                #append results to results list\n",
    "                results.append({\n",
    "                    \"alpha\": a, \"k\": test_k, \"init\": i,\n",
    "                    \"flag_tx\": flags,\n",
    "                    \"tx_rate\": flags/total_tx,\n",
    "                   \"flag_cards\": len(cards),\n",
    "                    \"card_rate\": len(cards)/total_cards,\n",
    "                    \"gate\": gate\n",
    "                })\n",
    "\n",
    "#convert results to dataframe and sort\n",
    "ewma_df = pd.DataFrame(results).sort_values([\"tx_rate\",\"card_rate\",\"k\",\"init\",\"alpha\"])\n",
    "#inspect the first 10 rows\n",
    "ewma_df.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd92b331",
   "metadata": {},
   "source": [
    "### Interpret Results and Set Parameters\n",
    "\n",
    "Best results consistently used alpha = 0.1, so this will be chosen\n",
    "\n",
    "k between 5 and 5.5 keeps the rule quiet.\n",
    "\n",
    "The results are sorted from lowest flag rate, but realistically 1000 is too high of a gate as then we are only using EWMA for transactions between 1000 and 1500.\n",
    "\n",
    "A larger warm up period is better so we get a stable baseline before scoring\n",
    "\n",
    "Based on this we will set the parameters below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90b21cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lock in params\n",
    "CAP = 1500\n",
    "ALPHA = 0.1\n",
    "K = 5.25\n",
    "INITIAL = 10\n",
    "MIN_GATE = 850"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc693510",
   "metadata": {},
   "source": [
    "## Location Based Rule\n",
    "\n",
    "Try to detect 'impossible travel' by comparing the current tap to the previous one\n",
    "\n",
    "- map zipcode to (latitude, longitude) using a lookup table.\n",
    "- compute the haversine distance (distance on a sphere/globe) and time gap between taps \n",
    "- calculate the implied speed and flag if the result is over the set threshold\n",
    "\n",
    "No ground truths here either so again use Caixa data to control false positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92ed2894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ImpossibleTravel: 1158 tx flagged (0.01687%); distinct cards: 150 (3.69004%)\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import baseline_detector \n",
    "\n",
    "importlib.reload(baseline_detector)\n",
    "from baseline_detector import ZipToCoord, ImpossibleTravel\n",
    "\n",
    "#import zip code/lat/long file\n",
    "zip_csv_path = \"../data/raw/zip_lat_long.csv\"\n",
    "#instantiate ZipToCoord\n",
    "z2c = ZipToCoord(zip_csv_path)\n",
    "\n",
    "#instantiate ImpossibleTravel with initial params\n",
    "it = ImpossibleTravel(zip_lookup=z2c, vmax_kmh=500.0, min_km=100.0, min_dt_s=30.0)\n",
    "\n",
    "#decalre counters for flags, cards, and total tx\n",
    "flags = 0\n",
    "cards = set()\n",
    "n = 0\n",
    "\n",
    "#sort dataframe by card_id and timestamp, reset index to avoid multi-index issues\n",
    "dfs = dfc.sort_values([\"card_id\", \"timestamp\"]).reset_index(drop=True)\n",
    "\n",
    "#loop through dataset to count flags and unique cards\n",
    "for row in dfs.sort_values(\"timestamp\").itertuples():\n",
    "    f, info = it.update(row.card_id, row.timestamp, zip_code=row.zip, lat=None, lon=None)\n",
    "    n += 1\n",
    "    if f:\n",
    "        flags += 1\n",
    "        cards.add(row.card_id)\n",
    "\n",
    "#print results\n",
    "print(f\"ImpossibleTravel: {flags} tx flagged ({flags/n:.5%}); \"\n",
    "      f\"distinct cards: {len(cards)} ({len(cards)/dfc['card_id'].nunique():.5%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf9d067",
   "metadata": {},
   "source": [
    "### Tuning Location Rule\n",
    "\n",
    "Sweep a small grid of vmax_kmh, min_km, and min_dt_s on the Caixa dataset and report transaction flag rate and card flag rate. Based on the results we can adjust the perameters to those that are quietest while making sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b854e79e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vmax_kmh</th>\n",
       "      <th>min_km</th>\n",
       "      <th>min_dt_s</th>\n",
       "      <th>flags</th>\n",
       "      <th>tx_rate</th>\n",
       "      <th>card_rate</th>\n",
       "      <th>cards_flagged</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600</td>\n",
       "      <td>150</td>\n",
       "      <td>60</td>\n",
       "      <td>949</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.032718</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>600</td>\n",
       "      <td>150</td>\n",
       "      <td>90</td>\n",
       "      <td>949</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.032718</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>600</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>985</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>0.033948</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>600</td>\n",
       "      <td>100</td>\n",
       "      <td>90</td>\n",
       "      <td>985</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>0.033948</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>600</td>\n",
       "      <td>150</td>\n",
       "      <td>30</td>\n",
       "      <td>991</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>0.032718</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>600</td>\n",
       "      <td>75</td>\n",
       "      <td>60</td>\n",
       "      <td>1002</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>0.035178</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>600</td>\n",
       "      <td>75</td>\n",
       "      <td>90</td>\n",
       "      <td>1002</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>0.035178</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>600</td>\n",
       "      <td>100</td>\n",
       "      <td>30</td>\n",
       "      <td>1028</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>0.033948</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>600</td>\n",
       "      <td>75</td>\n",
       "      <td>30</td>\n",
       "      <td>1048</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.035424</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>500</td>\n",
       "      <td>150</td>\n",
       "      <td>60</td>\n",
       "      <td>1070</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>0.034686</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   vmax_kmh  min_km  min_dt_s  flags   tx_rate  card_rate  cards_flagged\n",
       "0       600     150        60    949  0.000138   0.032718            133\n",
       "1       600     150        90    949  0.000138   0.032718            133\n",
       "2       600     100        60    985  0.000144   0.033948            138\n",
       "3       600     100        90    985  0.000144   0.033948            138\n",
       "4       600     150        30    991  0.000144   0.032718            133\n",
       "5       600      75        60   1002  0.000146   0.035178            143\n",
       "6       600      75        90   1002  0.000146   0.035178            143\n",
       "7       600     100        30   1028  0.000150   0.033948            138\n",
       "8       600      75        30   1048  0.000153   0.035424            144\n",
       "9       500     150        60   1070  0.000156   0.034686            141"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set values to test for max speed, minimum distance, and minimum time delta\n",
    "v_maxs   = [500, 600]\n",
    "min_kms  = [75, 100, 150]\n",
    "min_dts  = [30, 60, 90]\n",
    "\n",
    "#find number of transactions and unique cards in the dataset\n",
    "n_tx = len(dfc)\n",
    "n_cards = dfc[\"card_id\"].nunique()\n",
    "\n",
    "#function to evaluate parameter combinations\n",
    "def eval_combo(vmax, min_km, min_dt):\n",
    "    #instantiate ImpossibleTravel with current parameters\n",
    "    it = ImpossibleTravel(zip_lookup=z2c, vmax_kmh=vmax, min_km=min_km, min_dt_s=min_dt)\n",
    "    #counter for flags and set for unique card ids\n",
    "    flags = 0\n",
    "    cards = set()\n",
    "    #iterate through dataframe\n",
    "    for row in dfs.itertuples():\n",
    "        #add flag to counter if update returns True\n",
    "        f, _ = it.update(row.card_id, row.timestamp, zip_code=row.zip)\n",
    "        if f:\n",
    "            flags += 1\n",
    "            cards.add(row.card_id)\n",
    "    #return a dictionary with the results\n",
    "    return {\n",
    "        \"vmax_kmh\": vmax,\n",
    "        \"min_km\": min_km,\n",
    "        \"min_dt_s\": min_dt,\n",
    "        \"flags\": flags,\n",
    "        #safe division to avoid division by zero\n",
    "        \"tx_rate\": flags / n_tx if n_tx else 0.0,\n",
    "        \"card_rate\": len(cards) / n_cards if n_cards else 0.0,\n",
    "        \"cards_flagged\": len(cards),\n",
    "    }\n",
    "\n",
    "rows = []\n",
    "#loop through each combination of parameters\n",
    "for vmax in v_maxs:\n",
    "    for mk in min_kms:\n",
    "        for md in min_dts:\n",
    "            rows.append(eval_combo(vmax, mk, md))\n",
    "\n",
    "#sort results\n",
    "sweep = pd.DataFrame(rows).sort_values(\n",
    "    [\"tx_rate\", \"card_rate\", \"min_km\", \"vmax_kmh\", \"min_dt_s\"]\n",
    ").reset_index(drop=True)\n",
    "#look at first 10 rows\n",
    "sweep.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4137fd",
   "metadata": {},
   "source": [
    "### Set Parameters\n",
    "\n",
    "- minimum distance of 150 seems to work the best\n",
    "- max velocity of 600 aslo works\n",
    "- set the minimum time gap to 60s as this seems like a reasonable timeframe for errors and retries to occur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de24b4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set final parameters\n",
    "V_MAX = 600\n",
    "MIN_KM = 150\n",
    "MIN_DT = 60"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696a2fc0",
   "metadata": {},
   "source": [
    "### Combine Rules\n",
    "\n",
    "Combine the above rules to generate a single edge flag if any of the rules fire. \n",
    "\n",
    "Flag = Merchant Spike OR Card Burst OR Amount flag OR Location Flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd0b217c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparkov: total tx with edge_flag=1: 2062\n"
     ]
    }
   ],
   "source": [
    "#import rule classes\n",
    "importlib.reload(baseline_detector)\n",
    "from baseline_detector import RuleCombiner, MerchantBaseline, CardBaseline, CardEWMA, AmountCap, ImpossibleTravel\n",
    "\n",
    "#instantiate rule combiner to raise flag for any rule firing\n",
    "comb = RuleCombiner(\n",
    "    merchant_baseline=MerchantBaseline(threshold=THRESHOLD_M),\n",
    "    card_baseline=CardBaseline(threshold=THRESHOLD_C),\n",
    "    card_ewma=CardEWMA(alpha=ALPHA, k=K, initial=INITIAL, min_gate=MIN_GATE),\n",
    "    amount_cap=AmountCap(cap=CAP),\n",
    "    travel = ImpossibleTravel(zip_lookup=z2c, vmax_kmh=V_MAX, min_km=MIN_KM, min_dt_s=MIN_DT)\n",
    ")\n",
    "\n",
    "#counter for flags\n",
    "edge_flag_count = 0\n",
    "\n",
    "#iterate through sparkov + synthetic dataset\n",
    "for row in df.itertuples():\n",
    "    #get transaction data\n",
    "    tx = {\n",
    "        \"timestamp\": row.timestamp,\n",
    "        \"merchant_id\": row.merchant_id,\n",
    "        \"card_id\": row.card_id,\n",
    "        \"amount\": getattr(row, \"amount\", 0.0),\n",
    "        \"zip\": getattr(row, \"zip\", None),\n",
    "        \"city\": getattr(row, \"city\", None),\n",
    "    }\n",
    "    #add flag to count if any rule fires\n",
    "    if comb.update(tx):\n",
    "        edge_flag_count += 1\n",
    "\n",
    "#print total flags raised\n",
    "print(\"Sparkov: total tx with edge_flag=1:\", edge_flag_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940fa121",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "The rules stay relatively quiet on the sparkov data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e75872",
   "metadata": {},
   "source": [
    "### Recap Final Parameter Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be5744f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THRESHOLD_M: 6 THRESHOLD_C: 3\n",
      "CAP: 1500 EWMA: {'alpha': 0.1, 'k': 5.25, 'initial': 10, 'min_gate': 850}\n",
      "Travel: {'vmax': 600, 'min_km': 150, 'min_dt': 60}\n"
     ]
    }
   ],
   "source": [
    "print(\"THRESHOLD_M:\", THRESHOLD_M, \"THRESHOLD_C:\", THRESHOLD_C)\n",
    "print(\"CAP:\", CAP, \"EWMA:\", {\"alpha\": ALPHA, \"k\": K, \"initial\": INITIAL, \"min_gate\": MIN_GATE})\n",
    "print(\"Travel:\", {\"vmax\": V_MAX, \"min_km\": MIN_KM, \"min_dt\": MIN_DT})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.13)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
