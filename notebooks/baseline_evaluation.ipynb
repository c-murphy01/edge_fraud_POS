{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e97f4e0",
   "metadata": {},
   "source": [
    "## BASELINE DETECTOR EVALUATION (MERCHANT)\n",
    "\n",
    "Evaluate the simple threshold rule for detecting velocity spikes in the sparkov + synthetic spikes dataset.\n",
    "\n",
    "# Method\n",
    "\n",
    " - Count number of unique cards per merchant in 30s buckets\n",
    " - Raise a flag if the count is greater than the set threshold\n",
    " - Compare predictions to the ground truth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804de7c5",
   "metadata": {},
   "source": [
    "# STREAMED DATA EVALUATION\n",
    "\n",
    "Stream the dataset once through, update the per merchant unique card count on each Tx, flag bucket once the count is greater than the threshold, calculate confusion matrix based on all merchant/bucket pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df0bfc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "#create absoulute path to notebook's. parent directory to src\n",
    "module_path = os.path.abspath(os.path.join('..', 'src'))\n",
    "#add to sys.path if not already there\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "#import detector wrapper functions\n",
    "from baseline_detector import MerchantBaseline, CardBaseline\n",
    "#import the merchant and card sets from truth tables\n",
    "from truth_tables import MERCHANT_SET, CARD_SET\n",
    "#inport evaluation helper functions\n",
    "from eval_funcs import threshold_predictions, per_bucket_confusion, precision_recall_f1, sweep_thresholds\n",
    "\n",
    "#ensure constistent d types\n",
    "DTYPES = {\"merchant_id\": str, \"card_id\": str}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbf9a7a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP 50 FP 0 FN 0 TN 1555392\n",
      "precision 1.000 recall 1.000 F1 1.000\n"
     ]
    }
   ],
   "source": [
    "# #read in spiked dataset, parsing timestamp as a time object, setting merchant and card ids to strings\n",
    "# #set low memory false to avoid incorrect data type inferences\n",
    "df = pd.read_csv(\n",
    "    \"../data/processed/sparkov_spikes.csv\",\n",
    "    parse_dates=[\"timestamp\"],\n",
    "    dtype=DTYPES,\n",
    "    low_memory=False\n",
    ")\n",
    "\n",
    "#define initial merchant spike baseline\n",
    "THRESHOLD_M = 6\n",
    "\n",
    "# #create instance of merchant baseline class\n",
    "mb = MerchantBaseline(threshold=THRESHOLD_M)\n",
    "\n",
    "#create empty sets for predictions and coverage\n",
    "predicted = set() #set of (merchant_id, bucket) that we flag\n",
    "all_buckets = set() #set of all (merchant_id, buckets) streamed in\n",
    "\n",
    "for row in df.itertuples():\n",
    "    #call the baseline wrapper class' update function\n",
    "    flag, info = mb.update(row.merchant_id, row.timestamp, row.card_id)\n",
    "    bucket = info[\"bucket\"]\n",
    "    #add each to the all bucekts set\n",
    "    all_buckets.add((row.merchant_id, bucket))\n",
    "    #add to flagged set if over threshold\n",
    "    if flag:\n",
    "        predicted.add((row.merchant_id, bucket))\n",
    "\n",
    "#find confusion matrix\n",
    "cm = per_bucket_confusion(predicted, MERCHANT_SET, all_buckets)\n",
    "#calc precision, recall, and f1 scores\n",
    "m  = precision_recall_f1(cm[\"tp\"], cm[\"fp\"], cm[\"fn\"])\n",
    "\n",
    "#print results\n",
    "print(f\"TP {cm['tp']} FP {cm['fp']} FN {cm['fn']} TN {cm['tn']}\")\n",
    "print(f\"precision {m['precision']:.3f} recall {m['recall']:.3f} F1 {m['f1']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35fb091",
   "metadata": {},
   "source": [
    "# Varied Threshold Test\n",
    "\n",
    "Precompute the unique cards per mechant/bucket, then sweep through different thresholds 2-16, calculate and compare results for each threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3473959c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'th': 2, 'tp': 50, 'fp': 2297, 'fn': 0, 'tn': 1553095, 'precision': 0.021303792074989347, 'recall': 1.0, 'f1': 0.04171881518564872}\n",
      "{'th': 3, 'tp': 50, 'fp': 2, 'fn': 0, 'tn': 1555390, 'precision': 0.9615384615384616, 'recall': 1.0, 'f1': 0.9803921568627451}\n",
      "{'th': 4, 'tp': 50, 'fp': 0, 'fn': 0, 'tn': 1555392, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0}\n",
      "{'th': 5, 'tp': 50, 'fp': 0, 'fn': 0, 'tn': 1555392, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0}\n",
      "{'th': 6, 'tp': 50, 'fp': 0, 'fn': 0, 'tn': 1555392, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0}\n",
      "{'th': 7, 'tp': 50, 'fp': 0, 'fn': 0, 'tn': 1555392, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0}\n",
      "{'th': 8, 'tp': 50, 'fp': 0, 'fn': 0, 'tn': 1555392, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0}\n",
      "truth merchant spikes: 50\n",
      "merchant-buckets total: 1555442\n"
     ]
    }
   ],
   "source": [
    "#add a bucket column to the dataframe (flooring same as detector/truth table)\n",
    "df[\"bucket\"] = df[\"timestamp\"].dt.floor(\"30s\")\n",
    "\n",
    "#count unique cards per merchant\n",
    "counts_m = df.groupby([\"merchant_id\", \"bucket\"])[\"card_id\"].nunique()\n",
    "#convert to a dictionary of key: (merchant, bucket), value: count or unique cards\n",
    "counts_m_dict = {k: int(v) for k, v in counts_m.items()}\n",
    "#all merchant/bucket pairs (used to find number of true negatives)\n",
    "all_buckets = set(counts_m_dict.keys())\n",
    "\n",
    "results = sweep_thresholds(counts_m_dict, MERCHANT_SET, all_buckets, start=2, stop=8)\n",
    "for r in results:\n",
    "    print(r)\n",
    "\n",
    "print(\"truth merchant spikes:\", len(MERCHANT_SET))\n",
    "print(\"merchant-buckets total:\", counts_m.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e47121b",
   "metadata": {},
   "source": [
    "# Choose Threshold Going Forward\n",
    "\n",
    "Choose the lowest threshold that still gives good results, and is also likely safe agaisnt unseen data. In this case, a threshold from 4 to 16 gives the. same perfect results, so we will keep 6 as the baseline rule as it should be safe against unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe10a89d",
   "metadata": {},
   "source": [
    "# Caixa Dataset FP Test\n",
    "\n",
    "Run the Real-Life Dataset (Caixa) through the baseline detector.\n",
    "Keep/change the curresnt threshold rule based on results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba4ec375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "th=4: 254/6692434  (0.00380%)\n",
      "th=5: 10/6692434  (0.00015%)\n",
      "th=6: 1/6692434  (0.00001%)\n",
      "th=7: 0/6692434  (0.00000%)\n",
      "th=8: 0/6692434  (0.00000%)\n"
     ]
    }
   ],
   "source": [
    "#read in caixa datset\n",
    "dfc = pd.read_csv(\"../data/processed/caixa_pos_sorted.csv\",\n",
    "                  parse_dates=[\"timestamp\"],\n",
    "                  dtype={\"merchant_id\": str, \"card_id\": str},\n",
    "                  low_memory=False)\n",
    "\n",
    "#add a bucket column to the dataframe (flooring same as detector/truth table)\n",
    "dfc[\"bucket\"] = dfc[\"timestamp\"].dt.floor(\"30s\")\n",
    "#count unique cards per merchant\n",
    "counts_m_c = dfc.groupby([\"merchant_id\",\"bucket\"])[\"card_id\"].nunique()\n",
    "\n",
    "#for various threshold values\n",
    "for THRESHOLD in [4,5,6,7,8]:\n",
    "    #count number of merchant/bucket pairs flagged as fraud\n",
    "    num_flagged   = int((counts_m_c >= THRESHOLD).sum())\n",
    "    #number of total merchant/bucket pairs\n",
    "    total_buckets = int(counts_m_c.size)\n",
    "    #calculate rate of false positives\n",
    "    rate = num_flagged / total_buckets if total_buckets else 0.0\n",
    "    #print results\n",
    "    print(f\"th={THRESHOLD}: {num_flagged}/{total_buckets}  ({rate:.5%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a99b66",
   "metadata": {},
   "source": [
    "Threshold of 6 give almost perfect results with only 1 false positive, so we will keep this threshold going forward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c99df4",
   "metadata": {},
   "source": [
    "## BASELINE DETECTOR EVALUATION (CARD BURST)\n",
    "mirror of what was done above but this time for the card burst threshold rather than the merchant spike threshold.\n",
    "\n",
    "# Method\n",
    "\n",
    " - Count number of unique merchants per card in 30s buckets\n",
    " - Raise a flag if the count is greater than the set threshold\n",
    " - Compare predictions to the ground truth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625f7b4b",
   "metadata": {},
   "source": [
    "# STREAMED DATA EVALUATION\n",
    "\n",
    "Stream the dataset once through, update the per card unique mercahnt count on each Tx, flag bucket once the count is greater than the threshold, calculate confusion matrix based on all card/bucket pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3dcf66a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP 41 FP 0 FN 9 TN 1749\n",
      "precision 1.000 recall 0.820 F1 0.901\n"
     ]
    }
   ],
   "source": [
    "#set static baseline threshold of 4\n",
    "THRESHOLD_C = 4\n",
    "\n",
    "#create instance of card baseline class\n",
    "cb   = CardBaseline(threshold=THRESHOLD_C)\n",
    "\n",
    "#create empty sets for predictions and coverage\n",
    "predicted_cards = set() #set of card_ids that are flagged\n",
    "all_cards = set(df[\"card_id\"].astype(str)) #set of all card_ids\n",
    "\n",
    "\n",
    "for row in df.itertuples():\n",
    "    #call the baseline wrapper class' update function\n",
    "    flag, info = cb.update(row.card_id, row.timestamp, row.merchant_id)\n",
    "    #add to flagged set if over threshold\n",
    "    if flag:\n",
    "        predicted_cards.add(row.card_id)\n",
    "\n",
    "#find confusion matrix\n",
    "cm_c = per_bucket_confusion(predicted_cards, CARD_SET, all_cards)\n",
    "#calc precision, recall, and f1 scores\n",
    "m_c  = precision_recall_f1(cm_c[\"tp\"], cm_c[\"fp\"], cm_c[\"fn\"])\n",
    "\n",
    "#print results\n",
    "print(f\"TP {cm_c['tp']} FP {cm_c['fp']} FN {cm_c['fn']} TN {cm_c['tn']}\")\n",
    "print(f\"precision {m_c['precision']:.3f} recall {m_c['recall']:.3f} F1 {m_c['f1']:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8396e53",
   "metadata": {},
   "source": [
    "# Varied Threshold Test\n",
    "\n",
    "sweep through different thresholds 2-7, calculate and compare results for each threshold. Our seep thresholds function doesn't work here as the truth table isn't at the same key level as the counts dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31a727f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'th': 2, 'tp': 50, 'fp': 492, 'fn': 0, 'tn': 1257, 'precision': 0.09225092250922509, 'recall': 1.0, 'f1': 0.16891891891891891}\n",
      "{'th': 3, 'tp': 49, 'fp': 0, 'fn': 1, 'tn': 1749, 'precision': 1.0, 'recall': 0.98, 'f1': 0.98989898989899}\n",
      "{'th': 4, 'tp': 41, 'fp': 0, 'fn': 9, 'tn': 1749, 'precision': 1.0, 'recall': 0.82, 'f1': 0.9010989010989011}\n",
      "{'th': 5, 'tp': 0, 'fp': 0, 'fn': 50, 'tn': 1749, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0}\n",
      "{'th': 6, 'tp': 0, 'fp': 0, 'fn': 50, 'tn': 1749, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0}\n",
      "{'th': 7, 'tp': 0, 'fp': 0, 'fn': 50, 'tn': 1749, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0}\n"
     ]
    }
   ],
   "source": [
    "#counts unique merchants per card_id/bucket\n",
    "counts_c = df.groupby([\"card_id\", \"bucket\"])[\"merchant_id\"].nunique()\n",
    "#set up counts dictionary with key: card_id, buckey and value: unique merchant count\n",
    "counts_c_dict = {k: int(v) for k, v in counts_c.items()}\n",
    "#create set of all card_ids\n",
    "all_cards = set(df[\"card_id\"].astype(str))\n",
    "\n",
    "#define new functions for sweep of card thresholds\n",
    "def card_metrics_at(th):\n",
    "    #get prediced pairs (card_id, bucket)\n",
    "    pred_pairs = threshold_predictions(counts_c_dict, th)\n",
    "    #collapse the predicted pairs to just the card ids (which ones have been flagged)\n",
    "    pred_cards = {cid for (cid, _) in pred_pairs}\n",
    "\n",
    "    #calculste confusion at the card level (sets of card_ids)\n",
    "    cm = per_bucket_confusion(pred_cards, CARD_SET, all_cards)\n",
    "    #calculate evaluation metrics\n",
    "    m  = precision_recall_f1(cm[\"tp\"], cm[\"fp\"], cm[\"fn\"])\n",
    "    #return the threshold, confusion matrix and evaluation scores \n",
    "    #(** unpacks the dictionary to allow us to create a new one)\n",
    "    return {\"th\": th, **cm, **m}\n",
    "\n",
    "#print the results for each threshold\n",
    "for th in range(2, 8):\n",
    "    print(card_metrics_at(th))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64848123",
   "metadata": {},
   "source": [
    "# Choose Threshold Going Forward\n",
    "\n",
    "Choose the lowest threshold that still gives good results, in this case, a threshold from 5 to 7 gives the same perfect results, so we will use 5 as the baseline rule."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1b1b71",
   "metadata": {},
   "source": [
    "# Caixa Dataset FP Test\n",
    "\n",
    "Run the Real-Life Dataset (Caixa) through the baseline detector.\n",
    "Keep/change the curresnt threshold rule based on results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936d26de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "th=4: pair-rate 0/6825428 (0.00000%); card-rate 0/4065 (0.00000%)\n",
      "th=5: pair-rate 0/6825428 (0.00000%); card-rate 0/4065 (0.00000%)\n",
      "th=6: pair-rate 0/6825428 (0.00000%); card-rate 0/4065 (0.00000%)\n",
      "th=7: pair-rate 0/6825428 (0.00000%); card-rate 0/4065 (0.00000%)\n"
     ]
    }
   ],
   "source": [
    "#count of how many unique merchants each card has visited that window\n",
    "counts_c_c = dfc.groupby([\"card_id\",\"bucket\"])[\"merchant_id\"].nunique()\n",
    "\n",
    "#test several cart thresholds on the real data\n",
    "for TH in [4,5,6,7]:\n",
    "    #number of card/buckets that meet threshold\n",
    "    pair_flags = int((counts_c_c >= TH).sum())\n",
    "    #total number of card/bucket pairs\n",
    "    pair_total = int(counts_c_c.size)\n",
    "    #share of card/buckets flagged at thos threshold\n",
    "    pair_rate  = pair_flags / pair_total if pair_total else 0.0\n",
    "\n",
    "    #count of how many unique cards would be flagged at this threshold\n",
    "    #reset_index() turns card/bucket pairs into columns so we can extract card_id\n",
    "    cards_flagged = counts_c_c[counts_c_c >= TH].reset_index()[\"card_id\"].astype(str).nunique()\n",
    "    #total count of unique cards\n",
    "    total_cards   = dfc[\"card_id\"].astype(str).nunique()\n",
    "    #share of cards flagged at least once\n",
    "    card_rate     = cards_flagged / total_cards if total_cards else 0.0\n",
    "\n",
    "    #print results\n",
    "    print(f\"th={TH}: pair-rate {pair_flags}/{pair_total} ({pair_rate:.5%}); \"\n",
    "          f\"card-rate {cards_flagged}/{total_cards} ({card_rate:.5%})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af74979",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "Since there are no 'card bursts' in the Caixa dataset, there is nothing to detect so the threshold here does not matter."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.13)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
