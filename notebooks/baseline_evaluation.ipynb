{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e97f4e0",
   "metadata": {},
   "source": [
    "### BASELINE DETECTOR EVALUATION (MERCHANT)\n",
    "\n",
    "Evaluate the simple threshold rule for detecting velocity spikes in the sparkov + synthetic spikes dataset.\n",
    "\n",
    "## Method\n",
    "\n",
    " - Count number of unique cards per merchant in 30s buckets\n",
    " - Raise a flag if the count is greater than the set threshold\n",
    " - Compare predictions to the ground truth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804de7c5",
   "metadata": {},
   "source": [
    "## STREAMED DATA EVALUATION\n",
    "\n",
    "Stream the dataset once through, update the per merchant unique card count on each Tx, flag bucket once the count is greater than the threshold, calculate confusion matrix based on all merchant/bucket pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0bfc41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP 50 FP 0 FN 0 TN 1555588\n",
      "precision 1.000 recall 1.000 F1 1.000\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "#create absoulute path to notebook's. parent directory to src\n",
    "module_path = os.path.abspath(os.path.join('..', 'src'))\n",
    "#add to sys.path if not already there\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "#import MerchantWindow class from baseline_detector.py\n",
    "from baseline_detector import MerchantBaseline\n",
    "#import the merchant set from truth tables\n",
    "from truth_tables import MERCHANT_SET\n",
    "from eval_funcs import per_bucket_confusion, precision_recall_f1\n",
    "\n",
    "#set static baseline threshold of 10\n",
    "THRESHOLD = 10\n",
    "\n",
    "#read in spiked dataset, parsing timestamp as a time object, setting merchant and card ids to strings\n",
    "#set low memory false to avoid incorrect data type inferences\n",
    "df = pd.read_csv(\"../data/processed/sparkov_spikes.csv\",\n",
    "        parse_dates=[\"timestamp\"],\n",
    "        dtype={\"merchant_id\": str, \"card_id\": str},\n",
    "        low_memory=False,)\n",
    "\n",
    "#create instance of merchant baseline class\n",
    "mb   = MerchantBaseline(threshold=THRESHOLD)\n",
    "#create empty sets for predictions and coverage\n",
    "predicted = set() #set of (merchant_id, bucket) that we flag\n",
    "all_buckets = set() #set of all (merchant_id, buckets) streamed in\n",
    "\n",
    "\n",
    "for row in df.itertuples():\n",
    "    #call the baseline wrapper class' update function\n",
    "    flag, info = mb.update(row.merchant_id, row.timestamp, row.card_id)\n",
    "    bucket = info[\"bucket\"]\n",
    "    #add each to the all bucekts set\n",
    "    all_buckets.add((row.merchant_id, bucket))\n",
    "    #add to flagged set if over threshold\n",
    "    if flag:\n",
    "        predicted.add((row.merchant_id, bucket))\n",
    "\n",
    "#find confusion matrix\n",
    "cm = per_bucket_confusion(predicted, MERCHANT_SET, all_buckets)\n",
    "#calc precision, recall, and f1 scores\n",
    "m  = precision_recall_f1(cm[\"tp\"], cm[\"fp\"], cm[\"fn\"])\n",
    "\n",
    "#print results\n",
    "print(f\"TP {cm['tp']} FP {cm['fp']} FN {cm['fn']} TN {cm['tn']}\")\n",
    "print(f\"precision {m['precision']:.3f} recall {m['recall']:.3f} F1 {m['f1']:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35fb091",
   "metadata": {},
   "source": [
    "## Varied Threshold Test\n",
    "\n",
    "Precompute the unique cards per mechant/bucket, then sweep through different thresholds 2-16, calculate and compare results for each threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3473959c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'th': 2, 'tp': 50, 'fp': 2297, 'fn': 0, 'tn': 1553291, 'precision': 0.021303792074989347, 'recall': 1.0, 'f1': 0.04171881518564872}\n",
      "{'th': 3, 'tp': 50, 'fp': 2, 'fn': 0, 'tn': 1555586, 'precision': 0.9615384615384616, 'recall': 1.0, 'f1': 0.9803921568627451}\n",
      "{'th': 4, 'tp': 50, 'fp': 0, 'fn': 0, 'tn': 1555588, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0}\n",
      "{'th': 5, 'tp': 50, 'fp': 0, 'fn': 0, 'tn': 1555588, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0}\n",
      "{'th': 6, 'tp': 50, 'fp': 0, 'fn': 0, 'tn': 1555588, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0}\n",
      "{'th': 7, 'tp': 50, 'fp': 0, 'fn': 0, 'tn': 1555588, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0}\n",
      "{'th': 8, 'tp': 50, 'fp': 0, 'fn': 0, 'tn': 1555588, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0}\n",
      "{'th': 9, 'tp': 50, 'fp': 0, 'fn': 0, 'tn': 1555588, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0}\n",
      "{'th': 10, 'tp': 50, 'fp': 0, 'fn': 0, 'tn': 1555588, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0}\n",
      "{'th': 11, 'tp': 50, 'fp': 0, 'fn': 0, 'tn': 1555588, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0}\n",
      "{'th': 12, 'tp': 50, 'fp': 0, 'fn': 0, 'tn': 1555588, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0}\n",
      "{'th': 13, 'tp': 50, 'fp': 0, 'fn': 0, 'tn': 1555588, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0}\n",
      "{'th': 14, 'tp': 50, 'fp': 0, 'fn': 0, 'tn': 1555588, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0}\n",
      "{'th': 15, 'tp': 50, 'fp': 0, 'fn': 0, 'tn': 1555588, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0}\n",
      "{'th': 16, 'tp': 50, 'fp': 0, 'fn': 0, 'tn': 1555588, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0}\n",
      "truth spikes: 50\n",
      "num merchant-buckets: 1555638\n"
     ]
    }
   ],
   "source": [
    "#add a bucket column to the dataframe (flooring same as detector/truth table)\n",
    "df[\"bucket\"] = df[\"timestamp\"].dt.floor(\"30s\")\n",
    "\n",
    "#count unique cards per merchant\n",
    "counts = df.groupby([\"merchant_id\", \"bucket\"])[\"card_id\"].nunique()\n",
    "\n",
    "#convert to a dictionary of key: (merchant, bucket), value: count or unique cards\n",
    "counts_dict = {k: int(v) for k, v in counts.items()}\n",
    "#all merchant/bucket pairs (used to find number of true negatives)\n",
    "all_buckets = set(counts_dict.keys())\n",
    "\n",
    "from eval_funcs import sweep_thresholds\n",
    "\n",
    "results = sweep_thresholds(counts_dict, MERCHANT_SET, all_buckets, start=2, stop=16)\n",
    "for r in results:\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e47121b",
   "metadata": {},
   "source": [
    "## Choose Threshold Going Forward\n",
    "\n",
    "Choose the lowest threshold that still gives good results, in this case, a threshold from 4 to 16 gives the. same perfect results, so we will use 4 as the baseline rule."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe10a89d",
   "metadata": {},
   "source": [
    "## Caixa Dataset FP Test\n",
    "\n",
    "Run the Real-Life Dataset (Caixa) through the baseline detector.\n",
    "Keep/change the curresnt threshold rule based on results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba4ec375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "th=4: 254/6692434  (0.00380%)\n",
      "th=5: 10/6692434  (0.00015%)\n",
      "th=6: 1/6692434  (0.00001%)\n",
      "th=7: 0/6692434  (0.00000%)\n",
      "th=8: 0/6692434  (0.00000%)\n"
     ]
    }
   ],
   "source": [
    "#read in caixa datset\n",
    "dfc = pd.read_csv(\"../data/processed/caixa_pos_sorted.csv\",\n",
    "                  parse_dates=[\"timestamp\"],\n",
    "                  dtype={\"merchant_id\": str, \"card_id\": str},\n",
    "                  low_memory=False)\n",
    "\n",
    "#add a bucket column to the dataframe (flooring same as detector/truth table)\n",
    "dfc[\"bucket\"] = dfc[\"timestamp\"].dt.floor(\"30s\")\n",
    "#count unique cards per merchant\n",
    "counts_c = dfc.groupby([\"merchant_id\",\"bucket\"])[\"card_id\"].nunique()\n",
    "\n",
    "#for various threshold values\n",
    "for THRESHOLD in [4,5,6,7,8]:\n",
    "    #count number of merchant/bucket pairs flagged as fraud\n",
    "    num_flagged   = int((counts_c >= THRESHOLD).sum())\n",
    "    #number of total merchant/bucket pairs\n",
    "    total_buckets = int(counts_c.size)\n",
    "    #caklculate rate of false positives\n",
    "    rate = num_flagged / total_buckets if total_buckets else 0.0\n",
    "    #print results\n",
    "    print(f\"th={THRESHOLD}: {num_flagged}/{total_buckets}  ({rate:.5%})\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.13)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
